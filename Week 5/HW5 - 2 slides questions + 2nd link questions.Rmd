---
title: "Week 5 HW Qi"
author: "Qi Hao"
date: "2/15/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### 1. use rbenchmark package to assess if there is any performance difference between using apply, sapply, lapply, and a for loop. 
```{r }
setwd("/Users/qihao/OneDrive/博三下/PLS900")
load("polity_dataframe.rda")

### write a function called functiona to do the descriptive data
functiona <-function(alist){
  n = length(alist)
  numberNA = sum(is.na(alist))
  b = mean(alist, na.rm = T)
  c = median(alist, na.rm = T)
  d = max(alist, na.rm = T)
  e = min(alist, na.rm = T)
  f = sd(alist, na.rm = T)
  return(c(n,numberNA,b,c,d,e,f ))
}

### create a function for each of sapply, apply, lapply and for loop
sapplydf <- function(adataframe){
  df <- sapply(adataframe, functiona)
  rownames(df) <- c("n","numberNA", "mean","median","max","min","stdev")
  return(df)
}

applydf <- function(adataframe){
  df <- apply(adataframe, 2, functiona)
  rownames(df) <- c("n","numberNA", "mean","median","max","min","stdev")
  return(df)
}

lapplydf <- function(adataframe){
  df <- do.call(cbind, lapply(adataframe,functiona))
  rownames(df) <- c("n","numberNA", "mean","median","max","min","stdev")
  return(df)
}

fordf <- function(avector){
  df <- data.frame(democ = rep(0,7),autoc = rep(0,7), polity2 = rep(0,7), xconst = rep(0,7))
  for (i in avector){
    df[,i] <- functiona(polity[,i])
}
  rownames(df) <- c("n","numberNA", "mean","median","max","min","stdev")
  return(df)
}

### use benchmark to find out how they excel/suck
library(rbenchmark)
df <-polity[,c('democ','autoc','polity2','xconst')]
avect <- c('democ','autoc','polity2','xconst')
benchmark(replications = 10, fordf(avect),sapplydf(df),applydf(df),lapplydf(df))

```
#### use tapply and dplyr to calculate the mean, median, and stdev of democ and xconst for every year in the polity dataframe object
```{r }
library(dplyr)
### in the slides Shahryar showed democ but in the instruction said polity2, not sure which one, just go with democ
selecteddata <- group_by(polity[,c("year","democ","xconst")], year)
### I figured once i use summarise_all, i don't have to use tapply
by_year <- summarise_all(selecteddata, mean, na.rm = T)

by_year_me <- summarise_all(selecteddata, median, na.rm = T)

by_year_sd <- summarise_all(selecteddata, sd, na.rm = T)

result <- cbind(by_year,by_year_me[,2:3])
result <- cbind(result, by_year_sd[,2:3])
colnames(result) <- c("year","democ_mean","xconst_mean","democ_median","xconst_median","democ_sd","xconst_sd")
result
```
### Wickham functional programming (second link)
```{r }
### 1. Given a function, like "mean", match.fun() lets you find a function. Given a function, can you find its name? Why doesn’t that make sense in R?
### you cannot find its name because functions do not have to have names in R, such as anonymous functions.

### 2. Use lapply() and an anonymous function to find the coefficient of variation (the standard deviation divided by the mean) for all columns in the mtcars dataset.
lapply(mtcars, function(x) sd(x)/mean(x))

### 3. integration
integrate(function(x) x ^ 2 - x, 0, 10)
integrate(function(x) sin(x) + cos(x), -pi, pi)
integrate(function(x) exp(x) / x, 10, 20)

### 4. ...

### 1. Why are functions created by other functions called closures?
# Closures get their name because they enclose the environment of the parent function and can access all its variables.

### 2. What does the following statistical function do? What would be a better name for it? (The existing name is a bit of a hint.)
### the function is a Box-Cox transformation

### 3. What does approxfun() do? What does it return?
### it returns a function performing the linear (or constant) interpolation, which puts data of given coordinates into current data

### 4. What does ecdf() do? What does it return?
### returns a function that calculates the empirical cumulative distribution of a given observed discrete distribution.

### 5. Create a function that creates functions that compute the ith central moment of a numeric vector.
moment <- function(n){
  function(X){
    a <-mean((X-mean(X))^n)
    return(a)
  }
}
m1 <- moment(1)
m2 <- moment(2)

X <- runif(100)
stopifnot(all.equal(m1(X), 0))
stopifnot(all.equal(m2(X), var(X) * 99 / 100))


### 6. Create a function pick() that takes an index, i, as an argument and returns a function with an argument x that subsets x with i.
pick <- function(i) {
  function(x){
    return(x[[i]])
  }
}
lapply(mtcars, pick(5))
# should do the same as this
lapply(mtcars, function(x) x[[5]])

### 1. Implement a summary function that works like base::summary(), but uses a list of functions. Modify the function so it returns a closure, making it possible to use it as a function factory.
functlist <- list(min, median, mean, max)
sumfuns <- function(afunclist){
  function(x) lapply(afunclist, function(f) f(x))
}
summary1 <- sumfuns(functlist)
sapply(mtcars, summary1)
### 2. Which of the following commands is equivalent to with(x, f(z))?
###    I think it is b.
#x$f(x$z).
#f(x$z).
#x$f(z).
#f(z).
#It depends.

### 1. Instead of creating individual functions (e.g., midpoint(), trapezoid(), simpson(), etc.), we could store them in a list. If we did that, how would that change the code? Can you create the list of functions from a list of coefficients for the Newton-Cotes formulae?

## define composite 
composite <- function(f, a, b, n = 10, rule) {
  points <- seq(a, b, length = n + 1)
  
  area <- 0
  for (i in seq_len(n)) {
    area <- area + rule(f, points[i], points[i + 1])
  }
  area
}
### define newton_cotes
newton_cotes <- function(coef, open = FALSE) {
  n <- length(coef) -1            ### note that Wickham's orginal codes is wrong. need to -1 here. 
  
  function(f, a, b) {
    pos <- function(i) a + i * (b - a) / n
    points <- pos(seq.int(0, length(coef)-1))
    (b - a) / sum(coef) * sum(f(points) * coef)
  }
}
### use newton_cotes to create trepazoid, midpoint and simpson
trepazoid <- newton_cotes(c(1,1))
midpoint <- newton_cotes(c(0,1,0))
simpson <- newton_cotes(c(1,4,1))
composite(sin, 0, pi, n = 10, rule = trepazoid)
composite(sin, 0, pi, n = 10, rule = midpoint)
composite(sin, 0, pi, n = 10, rule = simpson)

### 2. The trade-off between integration rules is that more complex rules are slower to compute, but need fewer pieces. For sin() in the range [0, π], determine the number of pieces needed so that each rule will be equally accurate. Illustrate your results with a graph. How do they change for different functions? sin(1 / x^2) is particularly challenging.
numbervect <- c()
variancevect <- c()
for (i in 10:1000){
  t <- composite(sin, 0, pi, n = i, rule = trepazoid)
  m <- composite(sin, 0, pi, n = i, rule = midpoint)
  s <- composite(sin, 0, pi, n = i, rule = simpson)
  if (var(c(t,m,s)) > 0.000001){      ### it depends on what you mean by "equally accurate". var < 0.000001 is used
    numbervect <- c(numbervect, i)
    variancevect <- c(variancevect,var(c(t,m,s)))
  }
  else {
    break
  }
}
plot(numbervect, variancevect)
### so it looks like when the number of pieces is more than 35, the three methods tend to agree with each other with difference smaller than 0.000001
numbervect <- c()
variancevect <- c()
functionx <- function(x){
  return(sin(1 / x^2))
}
for (i in 2:20){
  t <- composite(functionx, pi, 6, n = i, rule = trepazoid)
  m <- composite(functionx, pi, 6, n = i, rule = midpoint)
  s <- composite(functionx, pi, 6, n = i, rule = simpson)
  if (var(c(t,m,s)) > 0.000001){      ### it depends on what you mean by "equally accurate". var < 0.000001 is used
    numbervect <- c(numbervect, i)
    variancevect <- c(variancevect,var(c(t,m,s)))
  }
  else{
    break
  }
}
plot(numbervect,variancevect)
## the answer to this question depends on which part of the functionx we are integrating over. if we want to integrate over places near zero, things get super complicated. but if we are integrating over places far away from zero, it looks that it only takes 5 pieces for the three selected methods to agree with an accuracy of 0.000001 level. 
```
### Wickham functions (first link)
```{r }

```
## R Markdown

